{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6156a1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8eb911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from brut_model import BaseModel\n",
    "from dataset_builders import ScaleCellDataset\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "# For reproducibility\n",
    "random_seed = 1869\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4b6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_training_history(history, ck_time, title='loss and accuracy evolution'):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    x = [i * ck_time for i in range(len(history['validation_loss']))]\n",
    "    ax1.plot(x, history['train_loss'], label='training_loss', alpha=0.5, c='g')\n",
    "    ax1.plot(x, history['validation_loss'], label='validation_loss', alpha=0.5, c='r')\n",
    "    ax1.set_ylabel('loss')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.legend()\n",
    "\n",
    "#     ax2.plot(x, history['train_accuracy'], label='training_accuracy', alpha=0.5, c='g')\n",
    "#     ax2.plot(x, history['validation_accuracy'], label='validation_accuracy', alpha=0.5, c='r')\n",
    "#     ax2.set_ylabel('accuracy')\n",
    "#     ax2.set_xlabel('epoch')\n",
    "#     ax2.legend()\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597132ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_hyper_parameters={\n",
    "    \n",
    "    'batch_size':10,\n",
    "    'validation_split':0.3,\n",
    "    \n",
    "    'learning_rate':0.0001,\n",
    "    'momentum':0.9,\n",
    "    \n",
    "    'nr_epochs': 30000, #8001,\n",
    "    \n",
    "    'checking_epochs': 10 # Save the model performances once at 10 epochs\n",
    "}\n",
    "\n",
    "Model_hyper_parameters={\n",
    "    'inp_shape':8,\n",
    "    'output_shape':4\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c3a2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial data \n",
    "nr_elements = 10000\n",
    "xa = []\n",
    "xb = []\n",
    "ta = []\n",
    "for i in range(nr_elements):\n",
    "    ax= [[random.uniform(-1, 20.7),random.uniform(-1, 20.7)],[random.uniform(-1, 20.7),random.uniform(-1, 20.7)]]\n",
    "    \n",
    "    #at = [[random.randint(1, 20),random.randint(1, 10)],[random.randint(1, 10),random.randint(1, 20)]]\n",
    "    at = [[random.randint(1, 20),0],[0,random.randint(1, 20)]]\n",
    "    bt = [[random.randint(1, 20),0],[0,random.randint(1, 20)]]\n",
    "    \n",
    "    bx = np.dot(np.linalg.inv(bt),np.dot(at,ax))\n",
    "    \n",
    "    xa.append(ax)\n",
    "    xb.append(bx)\n",
    "    ta.append(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a57c8052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15.869020672853061, 11.922455517212358],\n",
       " [13.1917101660962, 12.156955779850394]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc184a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([10, 8])\n",
      "Labels batch shape: torch.Size([10, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = ScaleCellDataset(xa,xb,ta)\n",
    "\n",
    "# Split the data \n",
    "\n",
    "batch_size = Training_hyper_parameters['batch_size']\n",
    "validation_split = Training_hyper_parameters['validation_split']\n",
    "shuffle_dataset = True\n",
    "\n",
    "\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "## Creating data loaders for trianing and vlaidation:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=len(val_indices),\n",
    "                                                sampler=valid_sampler)\n",
    "\n",
    "all_train =torch.utils.data.DataLoader(dataset, batch_size=len(train_indices), sampler=train_sampler)\n",
    "##  \n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c1f12",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8690f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "BaseModel(\n",
      "  (linear1): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (linear3): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (linear4): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (linear5): Linear(in_features=16, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[-0.1083,  0.1032,  0.0850,  0.0516,  0.0991, -0.0094,  0.1844,  0.0057],\n",
      "        [-0.1093, -0.1680,  0.1280,  0.1414, -0.3247,  0.0773, -0.0391,  0.2287],\n",
      "        [ 0.2473,  0.2065, -0.1322, -0.0566,  0.0549, -0.1923,  0.3427, -0.0707],\n",
      "        [ 0.3081,  0.1721,  0.0899, -0.3137, -0.1820,  0.1181,  0.0109,  0.3457],\n",
      "        [-0.3388, -0.1676,  0.3404,  0.1382,  0.1165, -0.3027,  0.1658, -0.0191],\n",
      "        [-0.3516, -0.0639,  0.3389, -0.1003,  0.2385, -0.2907,  0.0646,  0.3473],\n",
      "        [ 0.1248,  0.2825,  0.1357, -0.1180, -0.1327, -0.1694, -0.0421, -0.0409],\n",
      "        [ 0.2409, -0.0380, -0.1850,  0.1219,  0.3161, -0.1175, -0.2532, -0.2914],\n",
      "        [-0.2623, -0.3529,  0.2413, -0.0661,  0.1500,  0.2278,  0.2295,  0.0299],\n",
      "        [-0.3319, -0.1310,  0.0933,  0.1514,  0.3308,  0.2716,  0.3213,  0.0123],\n",
      "        [ 0.1351,  0.3190,  0.1860, -0.1271,  0.3234,  0.0635, -0.3312, -0.1857],\n",
      "        [-0.2115,  0.0372, -0.3248,  0.1514,  0.2890, -0.1217, -0.3421,  0.2843],\n",
      "        [-0.2234,  0.1047,  0.3102, -0.0067, -0.2056,  0.1433,  0.2777,  0.1721],\n",
      "        [ 0.3038,  0.3508,  0.2993,  0.1548, -0.2291, -0.3385, -0.2295, -0.0183],\n",
      "        [ 0.1247,  0.1501,  0.2987,  0.3222,  0.2909,  0.1169, -0.1534, -0.0472],\n",
      "        [-0.0856, -0.2218,  0.0080,  0.1394,  0.0279,  0.0743,  0.1080, -0.0908]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3209,  0.3325, -0.1659,  0.0354,  0.0557, -0.3274,  0.1963,  0.1276,\n",
      "         0.0751, -0.0095, -0.3242, -0.0695, -0.0745,  0.2532,  0.1833, -0.2565],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.4696e-01,  1.3034e-01, -1.3924e-01,  7.7967e-02,  8.4687e-03,\n",
      "          4.1362e-02, -1.0402e-01, -1.3765e-01,  3.2592e-02,  6.1083e-03,\n",
      "         -5.0472e-02, -1.9985e-01,  2.1130e-01,  2.2256e-01, -6.3607e-02,\n",
      "         -1.1602e-01],\n",
      "        [ 2.4408e-01,  1.7705e-01, -2.0717e-01, -1.6285e-01, -9.9721e-02,\n",
      "          1.0755e-01,  8.1695e-02, -1.3565e-01,  1.6357e-01,  2.2001e-01,\n",
      "          1.7183e-01, -1.8647e-01, -1.1438e-01,  2.2968e-01,  1.2078e-01,\n",
      "         -2.2210e-01],\n",
      "        [ 1.6306e-01, -1.2688e-01,  2.8335e-02, -7.4792e-02, -1.0305e-01,\n",
      "         -1.0269e-01,  1.8681e-01,  1.4725e-01,  1.8000e-01, -7.1434e-02,\n",
      "         -9.1629e-02, -1.9654e-01, -4.3612e-02,  1.9527e-02, -8.9484e-02,\n",
      "          1.5833e-01],\n",
      "        [ 8.6851e-03,  1.0764e-01, -5.8912e-03, -2.4768e-01, -1.9294e-01,\n",
      "          1.5869e-01, -1.8131e-01,  1.6817e-01,  1.7089e-01, -2.4165e-01,\n",
      "          1.6194e-01, -1.1848e-01, -1.3959e-01,  4.8190e-03,  2.0828e-01,\n",
      "         -2.0023e-01],\n",
      "        [-2.2468e-01,  8.6484e-02,  4.5709e-02,  1.5877e-01,  1.9883e-01,\n",
      "         -1.6434e-01,  9.3852e-02,  1.7896e-01,  2.4597e-01,  1.8250e-01,\n",
      "         -4.1195e-02,  1.5229e-01, -6.1850e-02, -1.9993e-01, -2.2428e-01,\n",
      "         -8.3059e-02],\n",
      "        [-1.5283e-01, -1.0865e-01,  1.7481e-01,  1.0484e-01, -2.3908e-01,\n",
      "         -8.7831e-02, -7.7000e-02,  1.2853e-01, -2.0070e-01, -1.1313e-01,\n",
      "          5.5906e-04,  2.1022e-01,  4.6408e-02, -1.4606e-01,  2.3813e-01,\n",
      "          7.7509e-02],\n",
      "        [ 1.2206e-01, -2.1085e-01, -2.0836e-01,  1.4919e-01,  1.8325e-01,\n",
      "         -5.5507e-02, -1.9029e-01,  1.6932e-01, -3.9350e-02, -3.2659e-02,\n",
      "          1.8798e-01,  7.0388e-02, -2.4986e-01, -5.7725e-02,  5.6047e-02,\n",
      "         -5.0487e-02],\n",
      "        [ 1.9251e-01, -2.3602e-02, -1.3987e-02, -4.3434e-02, -2.1386e-01,\n",
      "          1.0202e-01, -1.2502e-01, -1.0320e-01, -1.7539e-01,  1.0782e-01,\n",
      "          1.7252e-01,  6.8617e-02, -1.2560e-01, -2.1468e-01, -1.8464e-01,\n",
      "          1.7168e-01],\n",
      "        [ 1.0405e-01, -2.4881e-01,  1.6175e-01,  1.3927e-01,  9.8602e-02,\n",
      "         -1.1754e-01, -9.4799e-03,  4.6901e-02, -2.0945e-01, -2.5326e-03,\n",
      "         -1.4644e-01,  2.1557e-01, -2.1281e-01,  2.2176e-01,  1.2799e-01,\n",
      "         -3.7978e-02],\n",
      "        [ 9.6492e-02,  1.7471e-01,  5.4253e-03, -4.5826e-02,  2.2034e-01,\n",
      "         -1.3975e-01, -2.2980e-01, -1.4955e-01,  4.0370e-02, -2.6936e-02,\n",
      "          6.4842e-02,  1.2422e-01,  3.8741e-02,  5.6604e-02, -5.3592e-02,\n",
      "         -2.0613e-01],\n",
      "        [-9.9410e-02,  5.4749e-02, -1.2251e-01, -2.3717e-01, -1.0261e-01,\n",
      "         -8.4827e-02,  5.4598e-03, -1.2599e-01, -1.3357e-01, -2.4627e-01,\n",
      "         -1.2189e-02, -9.1326e-02, -2.0981e-01, -1.8849e-01, -3.5840e-02,\n",
      "         -2.2604e-01],\n",
      "        [-1.9473e-01, -6.7875e-02, -1.3772e-01,  2.1797e-01, -2.9901e-02,\n",
      "         -5.9556e-03, -1.5917e-01, -2.2063e-01,  1.2753e-01,  1.2000e-01,\n",
      "          7.5994e-02, -1.5903e-01, -4.2063e-02,  2.9152e-02,  1.1799e-01,\n",
      "          1.0979e-01],\n",
      "        [-8.4958e-02,  7.2360e-02,  1.8070e-01,  1.0483e-01, -5.6026e-02,\n",
      "          2.5796e-02, -4.5295e-03, -1.5532e-01, -7.1343e-02, -4.0557e-02,\n",
      "          1.3510e-01,  3.5919e-02,  2.3542e-01,  2.7398e-02,  3.2756e-02,\n",
      "         -5.9816e-02],\n",
      "        [-1.5546e-01, -1.9322e-01, -9.9387e-02,  1.2535e-02, -1.8835e-01,\n",
      "         -1.5986e-02, -6.8951e-02, -2.2616e-01,  2.1844e-01, -2.5813e-02,\n",
      "         -1.2942e-01, -2.4838e-01, -1.8957e-01,  2.1697e-03, -1.0331e-01,\n",
      "         -1.9702e-01],\n",
      "        [ 4.0439e-02, -2.1188e-01, -2.8035e-02,  6.6897e-02,  2.1159e-01,\n",
      "          1.2677e-01,  5.5662e-03, -1.9278e-01, -2.8721e-03,  1.2423e-01,\n",
      "          1.5221e-01, -5.1201e-02,  6.0617e-02,  1.1195e-01, -1.6304e-02,\n",
      "         -6.6672e-02],\n",
      "        [ 6.4163e-02, -6.1696e-02, -2.1779e-02,  6.1505e-02, -2.1893e-01,\n",
      "          1.9832e-01, -1.9835e-01,  2.0505e-01,  7.3280e-02, -2.4337e-01,\n",
      "         -1.1981e-01,  2.4550e-01, -2.3659e-01,  1.9811e-01, -3.0995e-02,\n",
      "          1.8968e-01],\n",
      "        [-2.1826e-01, -7.7082e-02, -2.1122e-01, -1.4721e-01,  9.3552e-02,\n",
      "         -9.3986e-02, -3.5459e-02,  1.0989e-01,  1.4552e-01,  1.2066e-01,\n",
      "         -5.4605e-02, -8.0512e-02,  5.4258e-02,  9.5880e-02, -7.7705e-02,\n",
      "         -9.5567e-02],\n",
      "        [-4.6591e-03,  1.7773e-01,  2.0628e-01, -2.0011e-01,  1.8103e-01,\n",
      "         -1.8839e-02, -3.0605e-02,  1.0945e-01, -4.3744e-02, -1.5134e-02,\n",
      "         -3.2577e-02, -6.5913e-02,  5.8187e-02, -1.4123e-04, -7.0739e-02,\n",
      "          1.3058e-01],\n",
      "        [-1.0964e-01,  1.8274e-01,  1.8818e-01, -2.2776e-01,  2.0734e-01,\n",
      "         -1.8026e-01, -1.6135e-01,  2.2742e-01,  7.7557e-03, -3.5069e-02,\n",
      "          2.0496e-01,  1.1470e-01, -2.0665e-01, -1.6563e-02,  2.0435e-01,\n",
      "          1.0079e-01],\n",
      "        [ 6.4996e-02, -1.0360e-01, -2.1293e-02,  1.0262e-01, -1.6626e-01,\n",
      "         -2.2526e-01, -1.1424e-01,  7.3695e-02, -5.0801e-02, -1.0710e-01,\n",
      "          2.3627e-01, -1.0367e-02,  8.5268e-02, -1.7036e-03,  6.4546e-02,\n",
      "          6.7587e-02],\n",
      "        [-2.0695e-01, -3.0028e-02, -1.1105e-02, -1.2100e-01,  2.4845e-01,\n",
      "          2.0426e-01, -9.7961e-02, -1.2347e-01, -1.0321e-01, -1.3901e-01,\n",
      "          2.5114e-02, -7.7276e-02,  6.0109e-02,  7.5084e-02,  1.4650e-01,\n",
      "          1.9514e-01],\n",
      "        [-2.3731e-01,  1.8317e-01,  1.3788e-01, -5.3391e-03,  6.7948e-03,\n",
      "          1.3506e-01,  1.9523e-01,  1.5436e-01, -3.3424e-03,  2.1251e-01,\n",
      "          1.1054e-02,  1.8035e-02,  3.1566e-02,  1.7226e-01, -1.2661e-01,\n",
      "         -1.7971e-01],\n",
      "        [ 7.9055e-02,  3.7253e-02, -1.0882e-01, -3.5831e-03, -1.6617e-01,\n",
      "          5.0537e-02, -1.8802e-02, -2.0379e-01, -5.0144e-02,  7.9252e-02,\n",
      "          1.0001e-01,  1.2787e-01, -7.9433e-03, -7.3574e-02,  1.2391e-01,\n",
      "         -2.3487e-01],\n",
      "        [-2.1716e-01, -1.3211e-01,  1.5633e-01, -1.0748e-01,  2.0835e-01,\n",
      "         -2.3501e-01, -1.4089e-01, -1.6223e-01, -2.1496e-01, -1.2730e-01,\n",
      "          2.1408e-01, -1.6201e-01, -1.9396e-01, -2.3854e-01,  1.3342e-01,\n",
      "         -2.2561e-01],\n",
      "        [ 1.2058e-01,  1.4441e-01, -1.8082e-01, -5.5452e-02, -1.2518e-02,\n",
      "          5.3309e-02, -1.1384e-01, -5.1954e-02, -2.2751e-01,  1.5748e-01,\n",
      "          1.9494e-01, -5.3573e-02,  1.4650e-02,  2.2889e-01,  1.8931e-01,\n",
      "         -2.3068e-01],\n",
      "        [-2.0919e-02, -1.0341e-01,  2.0154e-01, -1.2811e-01, -1.9479e-01,\n",
      "          1.2876e-01, -1.7499e-01,  4.5215e-02, -2.4309e-01, -1.2701e-01,\n",
      "         -1.1795e-01, -1.1635e-03,  4.0696e-02,  2.4509e-04,  1.2114e-01,\n",
      "         -3.5848e-02],\n",
      "        [ 1.3643e-01,  1.9088e-01, -6.5142e-02,  6.0800e-02, -1.6929e-01,\n",
      "          5.3529e-02, -1.8850e-01, -4.2260e-02, -1.5719e-01, -1.5445e-01,\n",
      "         -1.7776e-01,  7.2810e-02, -1.7442e-01,  2.2067e-01, -1.6064e-01,\n",
      "         -1.6121e-02],\n",
      "        [ 1.8077e-01,  1.3815e-01,  2.4298e-01,  5.2019e-03,  8.8866e-02,\n",
      "         -1.8445e-01,  9.1461e-02, -9.2786e-02,  1.6025e-01, -1.6898e-01,\n",
      "         -7.7956e-02, -1.9919e-01, -1.0022e-02,  1.2609e-01,  9.4640e-02,\n",
      "          6.0291e-02],\n",
      "        [ 8.6054e-02, -1.0304e-01, -6.0901e-02,  1.6329e-01,  6.7797e-02,\n",
      "          2.3520e-02, -1.4509e-01,  1.9625e-02, -1.7429e-01,  5.6053e-03,\n",
      "         -9.2507e-02,  1.0697e-01,  1.9490e-01, -1.4699e-01, -1.7158e-01,\n",
      "         -1.0908e-01],\n",
      "        [-1.8817e-01,  4.7820e-02,  1.2533e-01,  1.0103e-01,  1.1331e-01,\n",
      "         -6.6178e-02,  1.7102e-01, -1.8619e-01, -1.5685e-01,  2.1489e-01,\n",
      "         -2.7928e-02,  9.5205e-02,  2.4146e-01,  2.0740e-01, -1.7511e-01,\n",
      "         -2.1888e-01],\n",
      "        [-8.7706e-02, -1.0012e-01,  1.4158e-01,  2.0848e-01, -2.4059e-01,\n",
      "         -8.0592e-02, -1.2965e-01, -2.7124e-02,  4.2482e-02,  2.0300e-01,\n",
      "          2.4968e-01, -3.0448e-02, -5.6708e-02,  2.2976e-01, -1.0532e-01,\n",
      "          1.7737e-01],\n",
      "        [ 1.8032e-01,  1.1267e-01, -9.7730e-03,  1.8383e-02,  3.4067e-02,\n",
      "          2.0847e-01,  2.1031e-01,  4.3136e-02,  1.8869e-01,  2.2472e-01,\n",
      "         -2.8395e-02, -1.6114e-02, -1.4028e-01, -1.8423e-01, -4.7489e-02,\n",
      "         -1.3353e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0923, -0.2061, -0.0129,  0.1468,  0.2341,  0.0328, -0.0996,  0.2214,\n",
      "         0.2143, -0.0765,  0.1892, -0.0862, -0.0677,  0.0376, -0.0157, -0.0257,\n",
      "         0.0903, -0.0082,  0.2151,  0.1877, -0.0594, -0.1774, -0.0865,  0.0321,\n",
      "         0.1363,  0.1188,  0.1451, -0.2442, -0.1496, -0.2204,  0.0117,  0.1060],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0258,  0.1545,  0.1557,  ..., -0.0701, -0.1082,  0.1556],\n",
      "        [ 0.1080, -0.0752,  0.0092,  ...,  0.0411,  0.0579,  0.1561],\n",
      "        [-0.0489,  0.0984,  0.0252,  ..., -0.1080,  0.0821, -0.1404],\n",
      "        ...,\n",
      "        [ 0.1438,  0.1517, -0.1612,  ...,  0.0204,  0.1434, -0.0247],\n",
      "        [ 0.0578, -0.0833, -0.1140,  ...,  0.0087, -0.1149,  0.0939],\n",
      "        [ 0.0480, -0.0132,  0.0116,  ..., -0.1239, -0.1702, -0.1656]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1295, -0.0991,  0.0878,  0.0726, -0.0496, -0.1486, -0.1341, -0.1610,\n",
      "         0.0565,  0.0845,  0.0679, -0.0563, -0.1218, -0.1619, -0.1589, -0.0637,\n",
      "         0.1393,  0.0190, -0.0303, -0.0547,  0.0400, -0.0800, -0.1578,  0.0488,\n",
      "         0.0584,  0.1578, -0.0529,  0.0874, -0.1513,  0.0785, -0.0207,  0.0631],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-5.2840e-02, -1.3526e-01,  1.6210e-01,  1.4560e-01, -7.8124e-02,\n",
      "          2.1520e-02, -8.1777e-02, -3.6580e-02, -2.3456e-02, -9.3013e-02,\n",
      "          1.7631e-01,  2.7739e-02,  1.6761e-03,  1.6047e-01,  3.0041e-02,\n",
      "         -2.4434e-02, -6.9302e-02, -1.6148e-01, -1.4105e-01, -8.4164e-02,\n",
      "         -1.3145e-01,  2.4329e-02, -6.9476e-02, -2.5558e-02,  7.9165e-02,\n",
      "          1.0684e-01,  9.2437e-02, -1.2770e-01, -1.6585e-01, -7.1204e-02,\n",
      "          4.2014e-02,  4.9731e-02],\n",
      "        [-5.9804e-02, -9.8345e-02, -2.5605e-03, -5.2446e-02, -8.5153e-02,\n",
      "          1.6443e-01, -9.3092e-02, -1.2848e-01, -1.0906e-01, -9.6379e-02,\n",
      "         -1.5036e-01,  4.9749e-02,  1.1288e-01,  5.4910e-02,  1.6166e-01,\n",
      "          6.8204e-02, -1.7537e-01, -1.6519e-03,  2.1222e-02, -9.4808e-02,\n",
      "          2.0381e-02,  1.1571e-01, -7.0387e-02, -1.0864e-02,  3.9598e-03,\n",
      "         -4.1028e-02, -1.1449e-01,  1.5275e-01, -9.4329e-02,  1.2350e-01,\n",
      "         -1.1679e-01,  1.2746e-01],\n",
      "        [ 1.4361e-01,  1.6728e-01,  1.1034e-01,  1.3766e-01, -2.4963e-02,\n",
      "          4.4339e-02, -6.5468e-02, -1.7418e-01, -1.5015e-01, -1.3275e-01,\n",
      "         -1.0114e-01,  1.2304e-01, -8.8411e-02, -3.5673e-02, -1.3338e-01,\n",
      "          7.3289e-02, -8.0409e-02, -6.4526e-02, -1.1354e-01, -2.6071e-02,\n",
      "         -1.1581e-01,  3.4579e-03,  9.7181e-02, -1.4951e-01,  4.0047e-02,\n",
      "         -5.0583e-02,  1.5058e-01, -8.9465e-02,  1.7193e-01,  4.9784e-03,\n",
      "          1.0061e-01,  6.4187e-02],\n",
      "        [ 8.3214e-02, -1.5374e-01,  1.1063e-01,  4.1480e-02, -1.6445e-01,\n",
      "         -1.5986e-01,  4.1956e-02, -1.7079e-01, -9.6532e-02, -1.6790e-01,\n",
      "         -1.4081e-01,  6.3416e-02, -1.5914e-02, -6.9802e-02,  1.7404e-01,\n",
      "          5.1605e-02, -1.6494e-01, -1.2180e-01, -5.9482e-02, -5.5231e-02,\n",
      "          1.6662e-01, -4.8459e-02,  3.4795e-02,  1.1536e-01,  4.7438e-02,\n",
      "          4.4290e-02,  1.4272e-01, -1.3306e-01,  1.3193e-01,  4.2623e-03,\n",
      "          6.8140e-02,  8.7628e-02],\n",
      "        [ 6.2529e-02, -5.6979e-03,  1.4368e-01, -5.9637e-02, -1.2191e-01,\n",
      "          8.7685e-02, -1.1308e-01,  1.0425e-01,  1.5480e-01,  6.1812e-02,\n",
      "         -5.3295e-02,  1.0836e-01,  5.3066e-02,  7.7148e-02,  1.0274e-01,\n",
      "          7.5943e-02, -7.3496e-04,  1.7466e-02, -6.5207e-02, -6.8979e-03,\n",
      "         -1.3379e-01,  7.7024e-02,  4.4537e-02,  3.3029e-02, -6.6451e-02,\n",
      "         -7.4883e-02, -1.7126e-01, -1.2179e-01, -1.7570e-01,  7.7540e-02,\n",
      "         -6.3513e-02,  7.6314e-02],\n",
      "        [-9.7721e-02, -1.6927e-01,  1.1069e-01,  6.4479e-02, -8.6420e-02,\n",
      "          7.6075e-04, -8.9993e-02,  1.5155e-01,  1.0378e-01, -1.1566e-01,\n",
      "          1.0075e-01,  1.5935e-02,  2.7662e-02,  7.3621e-02,  3.0659e-02,\n",
      "          1.6905e-01, -5.7190e-03, -9.8619e-02,  3.0321e-02,  6.3895e-02,\n",
      "          1.4875e-01, -1.4147e-02,  1.0502e-01,  9.2529e-02, -7.2052e-02,\n",
      "         -1.6300e-01, -6.8668e-02, -1.6281e-01,  1.0326e-02,  9.3292e-02,\n",
      "          1.2553e-01, -1.7004e-01],\n",
      "        [-9.0853e-02, -1.6587e-01, -1.5725e-01,  6.2911e-02,  1.6333e-01,\n",
      "         -1.4767e-01,  1.4498e-01, -1.5755e-01, -5.2510e-02, -1.2581e-01,\n",
      "         -7.3901e-02, -7.5194e-02,  1.0998e-01, -1.0147e-01,  1.4446e-01,\n",
      "         -1.5982e-01,  1.0065e-01,  1.4244e-01,  2.0897e-02,  1.2515e-02,\n",
      "          8.3714e-02,  8.0070e-02,  1.1229e-01, -2.6579e-02, -1.5224e-01,\n",
      "          1.3594e-01,  1.8807e-02, -2.4121e-02, -8.5507e-02,  4.7285e-02,\n",
      "         -3.8488e-02, -1.1650e-04],\n",
      "        [-6.9868e-02,  1.1597e-01,  1.5546e-01, -1.1903e-01,  8.1821e-02,\n",
      "          1.0522e-01,  1.5014e-01, -1.2927e-02, -1.7824e-02,  6.1680e-02,\n",
      "         -9.5936e-02,  1.4608e-01, -3.3538e-02, -1.1546e-02, -4.7048e-02,\n",
      "          6.2882e-02, -1.6418e-01, -1.5299e-01, -1.7331e-01,  2.2789e-02,\n",
      "         -1.8623e-02, -1.4992e-01, -6.6593e-02, -8.7074e-02,  1.7172e-01,\n",
      "          8.4883e-02,  1.6254e-01,  3.7057e-02, -1.6129e-01, -5.1259e-02,\n",
      "          1.6437e-01,  9.0630e-02],\n",
      "        [-3.6080e-02, -1.0064e-01, -1.4607e-01,  1.1767e-01,  7.0130e-02,\n",
      "         -8.0184e-02, -1.3999e-02,  1.3134e-01,  1.1468e-01,  1.4323e-01,\n",
      "          1.6104e-01, -9.0495e-02, -8.4445e-02, -8.9900e-02, -9.6491e-02,\n",
      "          1.5275e-01, -1.3189e-01, -1.9711e-02,  6.7450e-02,  3.3360e-02,\n",
      "          1.9139e-02, -1.5111e-01,  6.0532e-02, -1.0300e-01,  1.0730e-01,\n",
      "          2.9913e-02, -3.4894e-02,  1.1815e-01, -1.7352e-01,  4.2180e-02,\n",
      "         -1.5219e-01,  1.0185e-02],\n",
      "        [ 1.9419e-02,  1.7523e-01,  5.3254e-03, -8.0989e-02, -6.4971e-02,\n",
      "         -1.0419e-01, -1.6433e-01, -1.2362e-01,  1.6988e-01,  1.7487e-01,\n",
      "         -4.5465e-02, -1.6534e-01, -1.6045e-01, -1.2240e-02,  1.6743e-01,\n",
      "          1.2480e-01,  3.5872e-02, -1.2215e-01, -1.4136e-01,  1.7592e-01,\n",
      "         -1.5634e-01, -8.8561e-02,  1.6704e-01, -5.3511e-02, -4.0210e-02,\n",
      "          2.2326e-02, -6.5882e-02,  1.2517e-01,  1.0922e-01, -1.2692e-02,\n",
      "          2.6945e-02,  5.6638e-02],\n",
      "        [-2.2878e-02,  1.2450e-01,  1.2429e-01, -1.5209e-01, -1.6287e-01,\n",
      "          2.8329e-02,  1.4599e-01,  1.1793e-01,  3.1959e-02, -1.6875e-01,\n",
      "         -1.2204e-02, -1.3862e-01,  1.3460e-01,  1.1964e-01, -2.2631e-02,\n",
      "          1.3364e-01,  8.4055e-03, -1.0809e-01, -4.8898e-03,  1.0712e-01,\n",
      "         -8.2165e-02,  6.0771e-02,  2.1436e-02, -3.4521e-02,  1.5687e-01,\n",
      "         -9.4189e-02,  1.2790e-01,  7.8931e-02, -1.7934e-02, -1.4143e-01,\n",
      "          7.0615e-03,  1.0105e-01],\n",
      "        [ 9.0679e-03, -1.7920e-02, -2.9262e-02,  9.2676e-02, -1.1292e-01,\n",
      "         -1.2375e-01, -1.6901e-02, -1.1313e-01, -1.1430e-01, -1.6206e-01,\n",
      "          7.2791e-02,  5.9406e-02, -1.6897e-01,  6.8492e-02,  4.9936e-03,\n",
      "         -4.5298e-02, -1.2157e-01, -1.5887e-01, -1.6083e-02,  6.3138e-02,\n",
      "          1.1500e-01, -5.5194e-03, -3.9582e-02,  1.5053e-01, -9.3641e-02,\n",
      "          1.1182e-02,  7.8927e-03,  5.4863e-02,  1.1414e-01,  1.4906e-01,\n",
      "          1.7589e-01,  4.1198e-02],\n",
      "        [ 6.2360e-02, -1.2029e-01, -1.0414e-01, -1.2657e-01,  1.3572e-02,\n",
      "          1.1547e-01,  1.1685e-02,  5.6952e-02, -1.7311e-01, -1.5046e-02,\n",
      "         -1.0706e-01, -1.5320e-01, -8.6710e-02,  3.7922e-02,  1.5622e-01,\n",
      "          1.7159e-01, -4.2392e-02,  1.5611e-01, -2.4649e-02,  3.0358e-02,\n",
      "          9.4184e-02, -9.8556e-02,  1.1398e-01,  4.7251e-02, -1.2285e-01,\n",
      "         -1.9816e-02,  2.6988e-02,  3.1611e-02,  2.7041e-02,  7.7187e-02,\n",
      "          9.6183e-02,  1.3653e-01],\n",
      "        [ 1.3001e-01,  2.4553e-02, -8.1385e-02, -1.5831e-01,  1.1519e-02,\n",
      "         -1.0670e-01, -1.2907e-01,  5.6149e-02,  3.1335e-02,  1.6532e-02,\n",
      "         -2.1920e-03,  5.8616e-02,  1.2682e-01, -7.9960e-02, -1.3713e-01,\n",
      "         -1.5057e-01, -3.5549e-02,  9.4577e-02, -1.7660e-01,  1.2408e-01,\n",
      "          1.4403e-01,  1.7093e-01, -3.4436e-02,  1.0114e-01,  1.6819e-01,\n",
      "         -9.1248e-02,  2.6005e-02,  1.3803e-01,  1.1017e-01,  6.0093e-02,\n",
      "          4.6732e-02,  1.2827e-01],\n",
      "        [ 4.6482e-02, -1.9360e-02,  1.6964e-01, -1.5339e-01,  5.5647e-02,\n",
      "          1.3506e-01,  8.6528e-02,  9.9482e-03, -4.6256e-02, -9.2337e-02,\n",
      "         -1.6480e-01, -5.9234e-02, -1.6933e-01, -6.7663e-02, -1.2425e-01,\n",
      "          8.5650e-02,  1.1683e-02, -6.4771e-02,  9.5654e-02,  9.7034e-02,\n",
      "          5.9593e-02, -1.5891e-01,  1.4110e-02,  1.3042e-01,  5.4384e-02,\n",
      "         -1.0867e-01,  1.5525e-01, -7.9834e-02, -9.0142e-02, -1.6313e-01,\n",
      "          2.2248e-03,  3.3003e-02],\n",
      "        [ 8.9753e-02,  7.6993e-02, -1.1409e-01, -3.7688e-02,  2.2509e-02,\n",
      "         -7.2716e-02,  6.5577e-02, -1.3376e-01, -3.9634e-02, -9.3104e-02,\n",
      "          9.4074e-02, -4.3775e-02,  4.9677e-02,  6.4267e-02,  3.6067e-02,\n",
      "         -9.1596e-02, -1.5144e-01,  9.8923e-02, -9.7055e-03,  8.6069e-02,\n",
      "         -1.5226e-01,  8.6943e-02, -1.1773e-01, -2.7693e-02, -5.8727e-02,\n",
      "         -2.6302e-03, -1.0871e-01,  9.2900e-02,  1.5399e-01,  1.5202e-01,\n",
      "         -1.3695e-01,  4.0445e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1585,  0.0834,  0.1526, -0.0825, -0.1554,  0.0194,  0.0912, -0.0145,\n",
      "        -0.0380,  0.0388, -0.0077, -0.1637,  0.1560,  0.0679,  0.0912, -0.0457],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0521, -0.1258, -0.1796, -0.2436, -0.0185,  0.0093,  0.0416,  0.2354,\n",
      "          0.1776, -0.1015, -0.1967, -0.2171, -0.1307,  0.0678, -0.0356, -0.1500],\n",
      "        [ 0.1054,  0.0663, -0.1268,  0.0821,  0.1206, -0.0642,  0.0261,  0.0186,\n",
      "          0.2041,  0.2162,  0.1398,  0.2188, -0.0148,  0.1169, -0.0069,  0.1557],\n",
      "        [-0.1827,  0.0030,  0.0371,  0.0951, -0.0404, -0.1375, -0.1419, -0.2213,\n",
      "          0.0476,  0.0301,  0.0875, -0.1576,  0.1696, -0.2325, -0.0996, -0.1007],\n",
      "        [ 0.0230,  0.1848, -0.2105,  0.0181, -0.0236,  0.2175, -0.0574,  0.0141,\n",
      "         -0.1040, -0.1932,  0.1334, -0.2492, -0.2004,  0.1441, -0.1895, -0.0934]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1825, 0.2290, 0.0929, 0.1427], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Prepare a model \n",
    "\n",
    "model = BaseModel(Model_hyper_parameters) # The model that we wish to train.\n",
    "\n",
    "print('The model:')\n",
    "print(model)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08175aa",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b1cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function\n",
    "def human_loss(output, target):\n",
    "#     print(\"o\",output)\n",
    "#     print(\"t\",target)\n",
    "    a = torch.square(output-target)\n",
    "    cost = torch.sum(a)\n",
    "    return cost\n",
    "\n",
    "criterion = human_loss # nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = Training_hyper_parameters['learning_rate']\n",
    "momentum = Training_hyper_parameters['momentum']                             \n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00e486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1| loss:1727.31298828125\n",
      "Epoch 101| loss:318.7264404296875\n",
      "Epoch 201| loss:309.5958251953125\n",
      "Epoch 301| loss:305.5770568847656\n",
      "Epoch 401| loss:302.7877197265625\n",
      "Epoch 501| loss:300.90087890625\n",
      "Epoch 601| loss:300.0138854980469\n",
      "Epoch 701| loss:298.1723937988281\n",
      "Epoch 801| loss:296.77154541015625\n",
      "Epoch 901| loss:296.246826171875\n",
      "Epoch 1001| loss:295.3368225097656\n",
      "Epoch 1101| loss:294.7000427246094\n",
      "Epoch 1201| loss:294.6486511230469\n",
      "Epoch 1301| loss:292.91741943359375\n",
      "Epoch 1401| loss:292.21197509765625\n",
      "Epoch 1501| loss:291.03509521484375\n",
      "Epoch 1601| loss:290.5935363769531\n",
      "Epoch 1701| loss:290.3180847167969\n",
      "Epoch 1801| loss:289.4108581542969\n",
      "Epoch 1901| loss:288.76031494140625\n",
      "Epoch 2001| loss:287.8811340332031\n",
      "Epoch 2101| loss:287.0547180175781\n",
      "Epoch 2201| loss:286.96575927734375\n",
      "Epoch 2301| loss:285.91839599609375\n",
      "Epoch 2401| loss:284.807373046875\n",
      "Epoch 2501| loss:284.8484191894531\n",
      "Epoch 2601| loss:283.0626525878906\n",
      "Epoch 2701| loss:282.7388000488281\n",
      "Epoch 2801| loss:282.32196044921875\n",
      "Epoch 2901| loss:281.5837707519531\n",
      "Epoch 3001| loss:280.89715576171875\n",
      "Epoch 3101| loss:279.97314453125\n",
      "Epoch 3201| loss:279.71685791015625\n",
      "Epoch 3301| loss:278.94183349609375\n",
      "Epoch 3401| loss:279.40802001953125\n",
      "Epoch 3501| loss:278.50506591796875\n",
      "Epoch 3601| loss:277.5804443359375\n",
      "Epoch 3701| loss:277.3602294921875\n",
      "Epoch 3801| loss:276.38134765625\n",
      "Epoch 3901| loss:276.21173095703125\n",
      "Epoch 4001| loss:275.699951171875\n",
      "Epoch 4101| loss:275.0006408691406\n",
      "Epoch 4201| loss:274.3074951171875\n",
      "Epoch 4301| loss:274.07135009765625\n",
      "Epoch 4401| loss:273.74346923828125\n",
      "Epoch 4501| loss:273.017333984375\n",
      "Epoch 4601| loss:272.5957946777344\n",
      "Epoch 4701| loss:272.1214904785156\n",
      "Epoch 4801| loss:271.8427734375\n",
      "Epoch 4901| loss:271.3892822265625\n",
      "Epoch 5001| loss:270.8236389160156\n",
      "Epoch 5101| loss:270.34710693359375\n",
      "Epoch 5201| loss:270.37890625\n",
      "Epoch 5301| loss:270.3128662109375\n",
      "Epoch 5401| loss:269.71356201171875\n",
      "Epoch 5501| loss:269.4247741699219\n",
      "Epoch 5601| loss:268.8665771484375\n",
      "Epoch 5701| loss:268.3467102050781\n",
      "Epoch 5801| loss:267.8172302246094\n",
      "Epoch 5901| loss:267.64312744140625\n",
      "Epoch 6001| loss:267.2655944824219\n",
      "Epoch 6101| loss:266.8997497558594\n"
     ]
    }
   ],
   "source": [
    "# actual training \n",
    "\n",
    "## Work in progress ##\n",
    "\n",
    "nr_epochs = Training_hyper_parameters['nr_epochs']\n",
    "ck_time = Training_hyper_parameters['checking_epochs']\n",
    "\n",
    "history = {'train_loss':[],'validation_loss':[], 'train_accuracy':[] , 'validation_accuracy':[]}\n",
    "\n",
    "for epoch in range(nr_epochs):  \n",
    "    model.train(True)\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss/len(train_loader)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "        print('Epoch {}| loss:{}'.format(epoch + 1,train_loss ))\n",
    "    \n",
    "    if epoch % ck_time == 0:\n",
    "        \n",
    "        #training\n",
    "        for i, data in enumerate(all_train):\n",
    "            inputs_t, labels_t = data\n",
    "            outputs_t = model(inputs_t)\n",
    "            \n",
    "            tl = criterion(outputs_t, labels_t).detach().numpy()\n",
    "            \n",
    "        \n",
    "        history['train_loss'].append(tl)\n",
    "       \n",
    "        #validation\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            inputs_v, labels_v = data\n",
    "            outputs_v = model(inputs_v)\n",
    "            \n",
    "        vl = criterion(outputs_v, labels_v).detach().numpy()\n",
    "        \n",
    "        history['validation_loss'].append(vl)\n",
    "        \n",
    "        \n",
    "        \n",
    "print('-Training finished-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d88ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f602ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training evolution:\n",
    "\n",
    "fig_trainig_evolution = print_training_history(history, ck_time)\n",
    "\n",
    "# print(\"\\nModel performance:\")\n",
    "# for k in history:\n",
    "#     print(\"{}\".format(k),history[k][len(history[k])-1])\n",
    "# print(\"__________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_training_history(history, ck_time, title='loss and accuracy evolution', cut=400):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    x = [i * ck_time for i in range(len(history['validation_loss'][100:cut]))]\n",
    "    ax1.plot(x, history['train_loss'][100:cut], label='training_loss', alpha=0.5, c='g')\n",
    "    ax1.plot(x, history['validation_loss'][100:cut], label='validation_loss', alpha=0.5, c='r')\n",
    "    ax1.set_ylabel('loss')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.legend()\n",
    "    \n",
    "fig_trainig_evolution = print_training_history(history, ck_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0526c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0,1],[1,0]])\n",
    "b = np.array([[0,5],[5,0]])\n",
    "xa_v= torch.tensor([0.0,1.0,1.0,0.0,0.0,5.0,5.0,0.0])\n",
    "outputs_v = model(xa_v)\n",
    "print(torch.reshape(outputs_v,(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375fb735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
